Here‚Äôs an end-to-end step-by-step guide to set up Grafana + Prometheus + Alertmanager to monitor Kubernetes pod logs, resources, and send alerts ‚Äî with optional Loki integration for log visibility.

üß∞ TOOLS USED
Tool	Role
Prometheus	Collects metrics from pods/nodes
Alertmanager	Sends alerts via Email/Slack/etc.
Grafana	Dashboards & Alert visualization
Loki	(Optional) Centralized pod log monitoring
Promtail	(Optional) Sends logs to Loki

‚úÖ PART 1: Prerequisites
A running Kubernetes cluster (minikube, EKS, AKS, etc.)

kubectl configured

helm installed

‚úÖ PART 2: Deploy Prometheus + Grafana + Alertmanager Using Helm
‚¨áÔ∏è Step 1: Add Helm Repo

helm repo add prometheus-community https://prometheus-community.github.io/helm-charts
helm repo update
üöÄ Step 2: Install Prometheus Stack (includes Grafana & Alertmanager)


root@ip-172-31-47-40:~# kubectl create ns monitoring
namespace/monitoring created
root@ip-172-31-47-40:~# helm install prometheus prometheus-community/kube-prometheus-stack -n monitoring
NAME: prometheus
LAST DEPLOYED: Thu Aug 21 10:43:44 2025
NAMESPACE: monitoring
STATUS: deployed
REVISION: 1
NOTES:
kube-prometheus-stack has been installed. Check its status by running:
  kubectl --namespace monitoring get pods -l "release=prometheus"

Get Grafana 'admin' user password by running:

  kubectl --namespace monitoring get secrets prometheus-grafana -o jsonpath="{.data.admin-password}" | base64 -d ; echo

Access Grafana local instance:

  export POD_NAME=$(kubectl --namespace monitoring get pod -l "app.kubernetes.io/name=grafana,app.kubernetes.io/instance=prometheus" -oname)
  kubectl --namespace monitoring port-forward $POD_NAME 3000

Visit https://github.com/prometheus-operator/kube-prometheus for instructions on how to create & configure Alertmanager and Prometheus instances using the Operator.
================================================================================================================================================================

root@ip-172-31-33-113:~# kubectl get svc -n monitoring
NAME                                      TYPE        CLUSTER-IP       EXTERNAL-IP   PORT(S)                      AGE
alertmanager-operated                     ClusterIP   None             <none>        9093/TCP,9094/TCP,9094/UDP   6m28s
prometheus-grafana                        ClusterIP   10.100.148.45    <none>        80/TCP                       6m33s
prometheus-kube-prometheus-alertmanager   ClusterIP   10.100.76.209    <none>        9093/TCP,8080/TCP            6m33s
prometheus-kube-prometheus-operator       ClusterIP   10.100.5.219     <none>        443/TCP                      6m33s
prometheus-kube-prometheus-prometheus     ClusterIP   10.100.241.248   <none>        9090/TCP,8080/TCP            6m33s
prometheus-kube-state-metrics             ClusterIP   10.100.102.50    <none>        8080/TCP                     6m33s
prometheus-operated                       ClusterIP   None             <none>        9090/TCP                     6m28s
prometheus-prometheus-node-exporter       ClusterIP   10.100.95.61     <none>        9100/TCP                     6m33s

==============================================================================================================================================================
root@ip-172-31-33-113:~# kubectl patch svc prometheus-kube-prometheus-prometheus -n monitoring -p '{"spec": {"type": "NodePort"}}'
service/prometheus-kube-prometheus-prometheus patched
root@ip-172-31-33-113:~# kubectl get svc prometheus-kube-prometheus-prometheus -n monitoring
NAME                                    TYPE       CLUSTER-IP       EXTERNAL-IP   PORT(S)                         AGE
prometheus-kube-prometheus-prometheus   NodePort   10.100.241.248   <none>        9090:30667/TCP,8080:30093/TCP   11m
root@ip-172-31-33-113:~# kubectl get nodes -o wide
NAME                            STATUS   ROLES    AGE   VERSION               INTERNAL-IP     EXTERNAL-IP     OS-IMAGE                       KERNEL-VERSION                    CONTAINER-RUNTIME
ip-192-168-0-188.ec2.internal   Ready    <none>   19m   v1.32.7-eks-3abbec1   192.168.0.188   18.208.205.63   Amazon Linux 2023.8.20250818   6.1.147-172.266.amzn2023.x86_64   containerd://1.7.27

Prometheus
http://18.208.205.63:30667
machine_memory_bytes
================================================grafana dashboard
root@ip-172-31-33-113:~# helm repo add grafana https://grafana.github.io/helm-charts
helm repo update
"grafana" has been added to your repositories
Hang tight while we grab the latest from your chart repositories...
...Successfully got an update from the "grafana" chart repository
...Successfully got an update from the "prometheus-community" chart repository
Update Complete. ‚éàHappy Helming!‚éà
root@ip-172-31-33-113:~# helm install grafana grafana/grafana -n monitoring
NAME: grafana
LAST DEPLOYED: Sat Aug 23 10:27:31 2025
NAMESPACE: monitoring
STATUS: deployed
REVISION: 1
NOTES:
1. Get your 'admin' user password by running:

   kubectl get secret --namespace monitoring grafana -o jsonpath="{.data.admin-password}" | base64 --decode ; echo


2. The Grafana server can be accessed via port 80 on the following DNS name from within your cluster:

   grafana.monitoring.svc.cluster.local

   Get the Grafana URL to visit by running these commands in the same shell:
     export POD_NAME=$(kubectl get pods --namespace monitoring -l "app.kubernetes.io/name=grafana,app.kubernetes.io/instance=grafana" -o jsonpath="{.items[0].metadata.name}")
     kubectl --namespace monitoring port-forward $POD_NAME 3000

3. Login with the password from step 1 and the username: admin
#################################################################################
######   WARNING: Persistence is disabled!!! You will lose your data when   #####
######            the Grafana pod is terminated.                            #####
#################################################################################
You want to switch it to NodePort (like you did for Prometheus).

 Method 1: Patch existing service
kubectl patch svc grafana -n monitoring -p '{"spec": {"type": "NodePort"}}'
root@ip-172-31-33-113:~# kubectl get svc -n monitoring
NAME                                      TYPE        CLUSTER-IP       EXTERNAL-IP   PORT(S)                         AGE
alertmanager-operated                     ClusterIP   None             <none>        9093/TCP,9094/TCP,9094/UDP      32m
grafana                                   NodePort    10.100.32.230    <none>        80:32737/TCP                    15m

===========================================================
Step 3: Add Prometheus as a Data Source

In Grafana ‚Üí Menu (‚ò∞) ‚Üí Connections ‚Üí Data sources ‚Üí Add data source

Select Prometheus

In the HTTP URL field, enter:

http://prometheus-kube-prometheus-prometheus:9090

Leave default Access = Server (default)

Click Save & Test ‚Üí You should see "Data source is working" ‚úÖ
=====================================================================================
You‚Äôve added Prometheus as a data source in Grafana and started adding visualizations (panels).

================================================================

Next Steps After Grafana Setup
1. Explore Metrics & Dashboards

Learn PromQL (Prometheus Query Language):

CPU, memory, disk, pod restarts, network.
Top 5 pods by CPU usage:

topk(5, sum(rate(container_cpu_usage_seconds_total{container!="",pod!=""}[5m])) by (namespace, pod))


Show Memory usage % per node:

(sum(node_memory_MemTotal_bytes) - sum(node_memory_MemAvailable_bytes)) / sum(node_memory_MemTotal_bytes) * 100


Alert on Pod restarts > 3 in 10m:

increase(kube_pod_container_status_restarts_total[10m]) > 3

Practice writing queries in Prometheus UI, then build Grafana panels.

Import ready dashboards from Grafana Labs
:

Node Exporter (ID: 1860)

Kubernetes Cluster (ID: 315)

Pods & Deployments (ID: 6417)

Step 2: Import Dashboard============================================================================================================

In Grafana left menu ‚Üí Dashboards ‚Üí + Import.

You‚Äôll see a box with three options: Import via grafana.com ID, Upload JSON file, Paste JSON.

Paste one of the IDs:

For Node Exporter ‚Üí 1860

For Kubernetes Cluster ‚Üí 315

For Pods & Deployments ‚Üí 6417

Click Load.

Select your Prometheus datasource.

Click Import.
=====================================================================================================================
he error you‚Äôre hitting is because SMTP (email) isn‚Äôt configured in Grafana yet.

By default, Grafana does not ship with SMTP enabled ‚Äî you have to configure it in grafana.ini or via environment variables before email contact points will work.

üîπ Option 1: Configure SMTP for Email Alerts

Open Grafana config (depends on your setup):

Helm / kube-prometheus-stack: edit values under grafana.ini.smtp.

Docker: mount a custom grafana.ini.

Bare-metal: edit /etc/grafana/grafana.ini.

Add a section like this (example using Gmail):

[smtp]
enabled = true
host = smtp.gmail.com:587
user = youraddress@gmail.com
password = your-app-password   ; (generate from Gmail -> App passwords)
from_address = youraddress@gmail.com
from_name = Grafana Alerts
skip_verify = true


Restart Grafana:

kubectl rollout restart deployment grafana -n monitoring
======================================================================alerrmanager===============================================
Step 1: Open Alerting

In Grafana left sidebar ‚Üí Alerting ‚Üí Alert rules.

Click + New alert rule.

üîπ Step 2: Rule Details

Name: Pod Not Ready

Group: Kubernetes Alerts

Folder: Kubernetes (or create one)

Evaluate every: 1m

For: 5m (wait time before firing to avoid flapping)

üîπ Step 3: Add Query (PromQL)

Under Queries and expressions ‚Üí A

Datasource: Prometheus

Query:

sum by (namespace, pod) (
  kube_pod_status_ready{condition="true"} == 0
)


This returns 1 if a pod is not Ready.

Expression ‚Üí Reduce

Input: A

Function: last

Expression ‚Üí Threshold

Input: Reduce

Condition: IS ABOVE 0

üëâ This means: If any pod is not Ready for 5 minutes ‚Üí fire alert.

üîπ Step 4: Labels & Annotations

Labels:

severity: critical

team: devops

Annotations:

Summary: Pod {{ $labels.pod }} in {{ $labels.namespace }} not Ready

Description:

Pod {{ $labels.pod }} in namespace {{ $labels.namespace }} has been in NotReady state for 5m.

üîπ Step 5: Notification (Contact Point)

In Alert rule ‚Üí Notifications

Choose Contact point (Slack, Email, Webhook).

If you haven‚Äôt created one yet:

Go to Alerting ‚Üí Contact points ‚Üí + New contact point

Choose Slack/Webhook/Email (SMTP required for email).

üîπ Step 6: Save & Test

Click Save rule.

Scale down or delete a pod to test:

kubectl -n default delete pod <pod-name>


In Grafana ‚Üí Alerting ‚Üí Alert rules ‚Üí State ‚Üí you should see it firing.

Notification will be sent to your Contact Point.
==========================================================================end========================================================================

or

systemctl restart grafana-server


Test: In Grafana ‚Üí Alerting ‚Üí Contact points ‚Üí New ‚Üí Email ‚Üí enter a test address ‚Üí Send test notification.

‚ö†Ô∏è Note: Gmail requires an App Password (not your normal password).
